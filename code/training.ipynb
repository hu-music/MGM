{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2,3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'train' \n",
    "\n",
    "###--- data ---###\n",
    "path_data_root = './'\n",
    "path_train_data = os.path.join(path_data_root, 'train.npz')\n",
    "path_test_data = os.path.join(path_data_root, 'test.npz')\n",
    "path_dictionary =  os.path.join(path_data_root, 'dictionary.pkl')\n",
    "\n",
    "###--- training config ---###\n",
    "path_exp = './exp'\n",
    "batch_size = 64\n",
    "init_lr = 0.0005\n",
    "max_grad_norm = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "  dictionary = pickle.load(open(path_dictionary, 'rb'))\n",
    "  event2word, word2event = dictionary\n",
    "  train_data = np.load(path_train_data,allow_pickle=True)\n",
    "  return train_data, event2word, word2event, dictionary\n",
    "def get_test_data():\n",
    "  dictionary = pickle.load(open(path_dictionary, 'rb'))\n",
    "  event2word, word2event = dictionary\n",
    "  test_data = np.load(path_test_data,allow_pickle=True)\n",
    "  return test_data, event2word, word2event, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes: [56, 135, 18, 3, 87, 18, 25]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, event2word, word2event, dictionary = get_train_data()\n",
    "\n",
    "\n",
    "# config\n",
    "n_class = []\n",
    "for key in event2word.keys():\n",
    "    n_class.append(len(dictionary[0][key]))\n",
    "\n",
    "# log\n",
    "print('num of classes:', n_class)\n",
    "\n",
    "# unpack\n",
    "train_x = train_data['x']\n",
    "train_y = train_data['y']\n",
    "train_mask = train_data['mask']\n",
    "train_label = train_data['label']\n",
    "factor=np.load('factor.npy')  # repetition learning matrix\n",
    "\n",
    "# run\n",
    "start_time = time.time()\n",
    "#tempo chord barbeat type pitch duration velocity ins   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 73774, 4: 287070, 3: 152060, 1: 27852, 0: 21807})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>: [56, 135, 18, 3, 87, 18, 25]\n",
      "n_parameters: 8,627,611\n"
     ]
    }
   ],
   "source": [
    "net = TransformerModel(n_class)\n",
    "# info_load_model = (\"./exp/\",'60')\n",
    "# load model\n",
    "if info_load_model:\n",
    "    path_ckpt = info_load_model[0] # path to ckpt dir\n",
    "    loss = info_load_model[1] # loss\n",
    "    name = 'loss_' + str(loss)\n",
    "    path_saved_ckpt = os.path.join(path_ckpt, name + '_params.pt')\n",
    "    net.load_state_dict(torch.load(path_saved_ckpt),False)\n",
    "        \n",
    "# # init\n",
    "net= nn.DataParallel(net)\n",
    "net.to(device)\n",
    "net.train()\n",
    "n_parameters = network_paras(net)\n",
    "print('n_parameters: {:,}'.format(n_parameters))\n",
    "\n",
    "\n",
    "\n",
    "# # optimizers\n",
    "optimizer = optim.Adam(net.parameters(), lr=init_lr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batch: 8790 \n",
      "train_x: (562563, 120, 7) \n",
      "train_y: (562563, 120, 7) \n",
      "train_mask: (562563, 120)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbdbf1d723b4be198ef3e5445c69fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------4, 0.392686, 0.250256, 0.643726, 1.800636, 2.634145, 1.549636, 0.213727\n",
      "epoch: 1/1 | Loss: 0.7842369870317674 | time: 0:08:35.870620\n"
     ]
    }
   ],
   "source": [
    "num_batch = len(train_x) // batch_size\n",
    "print('num_batch:', num_batch,'\\ntrain_x:', train_x.shape,'\\ntrain_y:', train_y.shape,'\\ntrain_mask:', train_mask.shape)\n",
    "\n",
    "n_epoch = 1\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epoch):\n",
    "    acc_loss = 0\n",
    "    acc_losses = np.zeros(len(n_class)+1)\n",
    "    with tqdm(range(num_batch)) as bar:\n",
    "        for bidx in range(num_batch): # num_batch \n",
    "              # index\n",
    "            bidx_st = batch_size * bidx\n",
    "            bidx_ed = batch_size * (bidx + 1)\n",
    "              # unpack batch data\n",
    "            batch_x = train_x[bidx_st:bidx_ed]\n",
    "            batch_y = train_y[bidx_st:bidx_ed]\n",
    "            batch_mask = train_mask[bidx_st:bidx_ed]\n",
    "            batch_label= train_label[bidx_st:bidx_ed]\n",
    "            batch_mask1= factor[bidx_st:bidx_ed]  # repetition learning matrix\n",
    "            batch_x = torch.from_numpy(batch_x).long().to(device)\n",
    "            batch_y = torch.from_numpy(batch_y).long().to(device)\n",
    "            batch_label = torch.from_numpy(batch_label).long().reshape(len(batch_label),1).to(device)\n",
    "            batch_mask = torch.from_numpy(batch_mask).float().to(device)\n",
    "            batch_mask1 = torch.from_numpy(batch_mask1).float().to(device)\n",
    "\n",
    "            if isinstance(net, torch.nn.DataParallel):\n",
    "                net = net.module\n",
    "          # run\n",
    "            losses = net.train_step(batch_x, batch_y, batch_mask,batch_mask1,batch_label)\n",
    "            loss_1 = (losses[0] + losses[1] + losses[2] + losses[3] + losses[4] + losses[5] + losses[6]) / 7\n",
    "            loss_2=losses[7]\n",
    "            loss= (loss_1+loss_2)/2\n",
    "          # Update\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                clip_grad_norm_(net.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "          # print\n",
    "            sys.stdout.write('{}/{} | Loss: {:06f} | {:04f}, {:04f}, {:04f}, {:04f}, {:04f}, {:04f}, {:04f}, {:04f}\\r'.format(\n",
    "                bidx, num_batch, loss, losses[0], losses[1], losses[2], losses[3], losses[4], losses[5], losses[6],losses[7]))\n",
    "            sys.stdout.flush()\n",
    "            bar.update()\n",
    "          # acc\n",
    "            acc_losses += np.array([l.item() for l in losses])\n",
    "            acc_loss += loss.item()\n",
    "\n",
    "    # epoch loss\n",
    "    runtime = time.time() - start_time\n",
    "    epoch_loss = acc_loss / num_batch\n",
    "    acc_losses = acc_losses / num_batch\n",
    "    print('------------------------------------')\n",
    "    print('epoch: {}/{} | Loss: {} | time: {}'.format(\n",
    "        epoch+1, n_epoch, epoch_loss, str(datetime.timedelta(seconds=runtime))))\n",
    "    fn = int(epoch_loss * 10) * 10\n",
    "    torch.save(net.state_dict(), os.path.join('./', 'loss_' + str(fn)+'_params.pt'))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate repetition learning matrix (based on your dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=4\n",
    "# b=2\n",
    "# c=1\n",
    "# label_type_matrix=np.float32([[c,c,c,c,a,c,c],\n",
    "#      [c,c,c,c,a,c,c], \n",
    "#      [c,c,b,c,a,b,b], \n",
    "#      [c,c,b,c,a,b,b], \n",
    "#      [c,c,b,c,a,b,b]])\n",
    "\n",
    "# factor=np.ones((train_x.shape[0],train_x.shape[1],train_x.shape[2]))\n",
    "# for n in range(len(train_x)):\n",
    "#     for k in range(7):\n",
    "#         count=Counter(train_x[n][:,k])\n",
    "#         for j in range(len(train_x[n])):\n",
    "#             if train_x[n][j][k] !=0:\n",
    "#                 factor[n,j,k] = label_type_matrix[train_label[n]][k]*(1+count[train_x[n][j][k]]/(len(train_x[n])-count[0]))\n",
    "                \n",
    "# np.save('factor.npy',factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
